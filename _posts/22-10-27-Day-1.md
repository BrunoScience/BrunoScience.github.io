---
layout: post
title:  "Graph Compute, Day 1 -- fluency in use of the command line"
date:   2022-10-27 3:30:00
categories: 100Days
---


# 100 Days of learning -- Day 1

There's simply no end to the amount of *"sharpening the saw"* that is NECESSARY for your personal sysadmin tools in information technology ... get used to the fact that you simply can never know enough in this realm. It is now old news that software has eaten the world; you should also understand why data has replace capital and deep learning in a hybrid machine + human skill has become the dominant force in [self-]education. 

Automating your intelligence gathering with personal sysadmin toools is fundamentally about time management ... using machines effectively to give yourself enough time to relax and think ... optimizing every second of every day.

This means that things like [*fluency on the command line*](https://github.com/jlevy/the-art-of-command-line) has become absolutely essential prerequisite skill for all kinds of learning and communication nowadays. If you do ANY work in data wrangling OR the artificial intelligence of knowledge engineering OR Physics-informed neural networks, you will find that you simply need to be fluent in [basic Unix commands](https://en.wikipedia.org/wiki/List_of_Unix_commands) in order to "*make it to first base*" or *get into the game* ... without this command line fluency and ability to work in the world of containers, you will essentially be relegated to being able to only be a consumer of pre-digested information or the kind of pre-analyzed data which others feel like passing along [for their reasons].  Without this fluency, you are dependent -- you will be *spoon fed* re-gurgitated information which has been dished up for the masses who are prized for their accounts, insurance coverage and luxuriant pecuniary pelts.

You will probably want to go beyond simple fluency in [very basic knowledge of common Unix commands](https://en.wikipedia.org/wiki/List_of_Unix_commands) and develop your own repository of [notes on mastering the command line](https://github.com/BrunoScience/notes-on-the-art-of-command-line) and possibly contribute to the [main originating repository](https://github.com/jlevy/the-art-of-command-line]. The point of developing your own selection of notes and tips on using the command-line is to more effectively be in control of your own tools by continually *"sharpening this saw"*. 

The best way to develop fluency is *learn the HARD way* ... or to actually USE the commands or imitate commands that you come across in browsing [StackOverflow](https://stackoverflow.com/questions/tagged/command-line), [ServerFault](https://serverfault.com/questions/tagged/command-line-interface), [DevOps StackExchange](https://devops.stackexchange.com/questions/tagged/configuration) or [Unix/Linux StackExchange](https://unix.stackexchange.com/) forums ... of course, you really do need to KNOW what those commands are doing *and YOU KNOW that will not be true the first time that you have use a command* so, ... learn as much as you can beforehand and be sure to ***use*** [ExplainShell](https://explainshell.com/) to get a helpful breakdown of what commands, options, pipelines, etc might do.

### Understand pipelines and the general architecture of Linux

In order to understand what the shell controls or how/why it is controlled in a certain manner, we should understand Linux [and maybe some things about how Linux has been and still is developed]. Linux is not exactly the [original UNIX](https://www.cs.dartmouth.edu/~doug/reader.pdf); but it is very UNIX-like and perhaps better or what we should think of as [*modern Unix*](https://github.com/ibraheemdev/modern-unix). 

Practically speaking, we should try to be more familiar with [*modern* tools](https://github.com/ibraheemdev/modern-unix) because that includes being aware of common [trusted GNU Core Utilities](https://en.wikipedia.org/wiki/GNU_Core_Utilities) OR the [*old reliable* **standard-issue** [generally available in all UNIX distros] or common Unix tools](https://en.wikipedia.org/wiki/Category:Standard_Unix_programs).

Quite often, it is ***speed in execution*** ... often from [applications written in Rust](https://www.rust-lang.org/learn/get-started) or maybe reimagined or refactored in C which opens up the ability to bring in features that offer some semblance intelligence, eg perhaps a neural network search ... which drives much of the motivation behind the modern versions and improvements.  Of course, much of the development activity is simply a matter of *sharpening the old ax* with more effective workflow design to eliminate pitfalls or problems of the common [GNU Core Utilities](https://en.wikipedia.org/wiki/GNU_Core_Utilities) or [**standard-issue** [generally available in all distros] or common Unix tools](https://en.wikipedia.org/wiki/Category:Standard_Unix_programs). {***NOTE to self:*** *Learn R and level-up the old C skillset.*}

The [*modern* tools](https://github.com/ibraheemdev/modern-unix) will include:

* [broot](https://github.com/Canop/broot) ... is one fast application which illustrates the beauty of [Rust dev](https://www.rust-lang.org/learn/get-started) and [how open source dev communities work nowadays](https://dystroy.org/broot/community/#contribute). It is a far better way to navigate directories, although the scope of how [broot](https://github.com/Canop/broot) changes the game might seem at first to be somewhat intimidating and not just because how [it replaces ls (and its clones)](https://dystroy.org/broot/#replace-ls-and-its-clones) ... you can [get an overview of a directory, even a big one](https://dystroy.org/broot/#get-an-overview-of-a-directory-even-a-big-one) ... and when you [find a directory, you can cd right into it](https://dystroy.org/broot/#find-a-directory-then-cd-to-it) ... you [never have to lose track of file hierarchy while you search](https://dystroy.org/broot/#never-lose-track-of-file-hierarchy-while-you-search)... you can [manipulate your files](https://dystroy.org/broot/#manipulate-your-files) or [manage files with panels](https://dystroy.org/broot/#manage-files-with-panels) ... [preview files](https://dystroy.org/broot/#preview-files) or [apply a standard or personal command to a file](https://dystroy.org/broot/#apply-a-standard-or-personal-command-to-a-file) or [apply commands on several files](https://dystroy.org/broot/#apply-commands-on-several-files) or [sort, see what takes space](https://dystroy.org/broot/#sort-see-what-takes-space) and [check git statuses](https://dystroy.org/broot/#check-git-statuses) ... but, you should spend some time looking at the [full array of WHY you would want to master broot](https://dystroy.org/broot/)
* [bat](https://github.com/sharkdp/bat) ... a [cat](https://en.wikipedia.org/wiki/Cat_(Unix)) *concatenate* clone with syntax highlighting and [Git](https://git-scm.com/book/en/v2) integration, 
* [exa](https://the.exa.website/) ... [exa](https://the.exa.website/introduction) is a modern replacement for ls ... exa could be developed under a different set of assumptions than were around in the 1970s: a) computers are not the bottleneck, b) 256-colour terminals abound, c) old [ls](https://tldp.org/LDP/LG/issue48/fischer.html) is still there
* [lsd](https://github.com/Peltoche/lsd) ... ls **deluxe** ... a rewrite of [GNU ls](https://www.gnu.org/software/coreutils/manual/html_node/ls-invocation.html) with lots of added features like colors, icons, tree-view, more formatting options etc. The project is heavily inspired by the [super colorls](https://github.com/athityakumar/colorls) Ruby script project.
* [delta](https://github.com/dandavison/delta) ... syntax-highlighting pager for [Git](https://git-scm.com/book/en/v2), [diff](https://en.wikipedia.org/wiki/Diff), and [grep](https://en.wikipedia.org/wiki/Grep) output
* [dust](https://github.com/bootandy/dust) ... [du](https://en.wikipedia.org/wiki/Du_%28Unix%29) + rust = dust ... more intuitive disk utility ... use [deb-get](https://github.com/wimpysworld/deb-get) to install dust.
* [deb-get](https://github.com/wimpysworld/deb-get) ... an alternative to [apt-get](https://linux.die.net/man/8/apt-get) for software not (yet) officially packaged for Debian/Ubuntu, maybe software that is fast moving and newer versions are available from the vendor/project OR maybe you want to use some non-free software that Debian/Ubuntu cannot distribute due to licensing restrictions.
* [duf](https://github.com/muesli/duf) ... user-friendly disk usage utility with colorful output, that adjusts to your terminal's theme & width, sorts results according to your needs to group and filter devices and conveniently output results in JSON format.
* [fd](https://github.com/sharkdp/fd), 
* [ripgrep](https://github.com/BurntSushi/ripgrep) ... extremely fast alternative to simple [grep](https://en.wikipedia.org/wiki/Grep) which respects your gitignore ... ... of course, there's a [VS Code extension which utilizes ripgrep and fzf](https://github.com/rlivings39/vscode-fzf-quick-open)
* [ag](https://github.com/ggreer/the_silver_searcher) ... code-searching tool similar to [ack](https://beyondgrep.com/) which was itself designed to go beyond simple [grep](https://en.wikipedia.org/wiki/Grep), in being better for programmers with large heterogeneous trees of source code, ack is written in portable Perl 5 and takes advantage of the power of Perl's regular expressions ... since [ag](https://geoff.greer.fm/ag/) is implemented in C and uses [pthreads](https://en.wikipedia.org/wiki/Pthreads), [ag](https://geoff.greer.fm/ag/) is an order of magnitude faster in some cases and [getting even faster](https://geoff.greer.fm/ag/speed/).
* [fzf] ... general purpose command-line fuzzy finder which can be used with any list; files, command history, processes, hostnames, bookmarks, git commits, etc ... of course, there's a [VS Code extension which utilizes ripgrep and fzf](https://github.com/rlivings39/vscode-fzf-quick-open)
* [mcfly](https://github.com/cantino/mcfly) ... replaces your default [ctrl-r shell history search](https://unix.stackexchange.com/questions/541/best-way-to-search-through-shells-history) with an ***intelligent*** search engine that takes into account your working directory and the context of recently executed commands. The key point of interest in this [Rust](https://www.rust-lang.org/learn/get-started)  application iss smart command prioritization powered by a small neural network that runs *fast* in real time.
* [choose](https://github.com/theryangeary/choose) ... human-friendly and **fast**, ie written in [Rust](https://www.rust-lang.org/learn/get-started), alternative to [cut](https://en.wikipedia.org/wiki/Cut_(Unix)), *and (sometimes) [awk](https://en.wikipedia.org/wiki/AWK)*, to extract sections from each line of input.
* [jq](https://stedolan.github.io/jq/) ... an [application written in C](https://github.com/stedolan/jq/wiki) that performs similarly to [sed](https://en.wikipedia.org/wiki/Sed) for JSON data to slice / filter / map / transform structured data with the same ease of [sed](https://en.wikipedia.org/wiki/Sed), awk](https://en.wikipedia.org/wiki/AWK), [grep](https://en.wikipedia.org/wiki/Grep) and other text-processing utilities that are part of the [set of common, *standard-issue* Unix commands](https://en.wikipedia.org/wiki/List_of_Unix_commands).
* [sd](https://github.com/chmln/sd) ... another ***more intuitive*** [application written in Rust](https://www.rust-lang.org/learn/get-started) which is an intuitive *find and replace* command line interface; [sd](https://github.com/chmln/sd) uses regex syntax to focus on doing one thing and doing it well.
* [cheat](https://github.com/cheat/cheat) ... allows for creation and viewing of interactive cheatsheets on the command-line. It was designed to help remind *nix system administrators of options for commands that they use frequently, but not frequently enough to remember.
* [tldr](https://github.com/tldr-pages/tldr) ... collection of community-maintained help pages for command-line tools or cheatsheets which aim to be a simpler, more approachable complement to traditional [man pages](https://en.wikipedia.org/wiki/Man_page)
* [bottom](https://clementtsang.github.io/bottom/nightly/) ... cross-platform graphical process/system monitor
* [glances], 
* [gtop], 
* [hyperfine], 
* [gping], 
* [procs], 
* [httpie], 
* [curlie], 
* [xh], 
* [zoxide], 
* [dog](https://github.com/ogham/dog) ... user-friendly command-line DNS client or DNS lookup utility, like [dig](https://www.diggui.com/dig-command-manual.php) on steroids 


We definitely will need to understand some key features of the UNIX philosophy or what an ideal Unix architecture concept is supposed to be:

* Unix systems use a centralized operating system kernel which manages system and process activities.
* All non-kernel software is organized into separate, kernel-managed processes; this also key for understanding containers and container management systems.
* Unix systems are preemptively multitasking: multiple processes can run at the same time, or within small time slices and nearly at the same time, and any process can be interrupted and moved out of execution by the kernel. Optimizing this thread management is essential for optimizing the performance of computation, which does not matter when we have 100X more compute power than we need -- it's a big deal when compute power limits what we can process.
* Files are stored on disk in a hierarchical file system, with a single top location throughout the system (root, or "/"), with both files and directories, subdirectories, sub-subdirectories, and so on below it. Finding our way around in this file structure is an essential prerequisite to doing anything.
* With few exceptions, devices and some types of communications between processes are managed and visible as files or pseudo-files within the file system hierarchy. This is known as UNIX's "*everything is a file*" philosophy. However, Linus Torvalds is absolutely right in correcting this inaccuracy and pointing out why it's best to think of ["*everything as a STREAM of bytes*"](https://yarchive.net/comp/linux/everything_is_file.html) rather than a file ... it is essential to understand [controlling the streams with ***pipelines***](https://www.gnu.org/software/bash/manual/html_node/Pipelines.html).


### You will NEVER actually be able to finish this pre-requisite lesson from Day 1

> The meta-lesson of this lesson about something as simple as Linux, the Linux development community and the community of open source developers developing better sysadmin tools is about the humility of learning from other human beings.

Of course, this lesson *should* PRECEED any serious work from the [curated list of AWESOME ***bash*** scripts and resources](https://github.com/awesome-lists/awesome-bash), ie because before even using a script, you should really understand what you trying to automate and where this is going to end up ... except, of course, as you use scripting you will learn how [your own fluency in mastering the command line](https://github.com/BrunoScience/notes-on-the-art-of-command-line) was and always will be far less than adequate. That is because this skill is fundamentally about trying to be better at learning how the best of several billion humans learn how to learn ... maybe you can almost learn to keep up with the smartest person you know, but this is really about trying to keep up with the smartest group of 1000 or so learners from the very smartest of smart 1,000,000 people you might be able to know. 
