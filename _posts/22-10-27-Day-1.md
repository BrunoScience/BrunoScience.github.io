---
layout: post
title:  "Graph Compute, Day 1 -- fluency in use of the command line"
date:   2022-10-27 3:30:00
categories: 100Days
---


# 100 Days of learning -- Day 1

There's simply no end to the amount of *"sharpening the saw"* that is NECESSARY for your personal sysadmin tools in information technology ... get used to the fact that you simply can never know enough in this realm. It is now old news that software has eaten the world; you should also understand why data has replace capital and deep learning in a hybrid machine + human skill has become the dominant force in [self-]education. 

Automating your intelligence gathering with personal sysadmin toools is fundamentally about time management ... using machines effectively to give yourself enough time to relax and think ... optimizing every second of every day.

This means that things like [*fluency on the command line*](https://github.com/jlevy/the-art-of-command-line) has become absolutely essential prerequisite skill for all kinds of learning and communication nowadays ... without this fluency, you will essentially be relegated to being able to only be a consumer of pre-digested information that others feel like passing along -- you will be *spoon fed* re-gurgitated information dished up for the harvested masses.

You will probably want to develop your own repository of [notes on mastering the command line](https://github.com/BrunoScience/notes-on-the-art-of-command-line) and possibly contribute to the [main repository](https://github.com/jlevy/the-art-of-command-line]. The point of developing your own selection of notes and tips on using the command-line is to more effectively be in control of your own tools by continually *"sharpening this saw"*. 

### Understand pipelines and the architecture of Linux

In order to understand what the shell controls or how/why it is controlled in a certain manner, we should understand Linux [and maybe some things about how Linux has been and still is developed]. Linux is not exactly the [original UNIX](https://www.cs.dartmouth.edu/~doug/reader.pdf); but it is very UNIX-like and perhaps better or what we should think of as [*modern Unix*](https://github.com/ibraheemdev/modern-unix) ... practically, we should be familiar with [*modern* tools](https://github.com/ibraheemdev/modern-unix) and that includes being aware of [standard Unix tools](https://en.wikipedia.org/wiki/Category:Standard_Unix_programs) which the modern version was designed to improve upon: 

* [bat](https://github.com/sharkdp/bat) ... a [cat](https://en.wikipedia.org/wiki/Cat_(Unix)) clone with syntax highlighting and [Git](https://git-scm.com/book/en/v2) integration, 
* [exa](https://the.exa.website/) ... [exa](https://the.exa.website/introduction) is a modern replacement for ls ... exa could be developed under a different set of assumptions than were around in the 1970s: a) computers are not the bottleneck, b) 256-colour terminals abound, c) old [ls](https://tldp.org/LDP/LG/issue48/fischer.html) is still there
* [lsd](https://github.com/Peltoche/lsd) ... ls **deluxe** ... a rewrite of [GNU ls](https://www.gnu.org/software/coreutils/manual/html_node/ls-invocation.html) with lots of added features like colors, icons, tree-view, more formatting options etc. The project is heavily inspired by the [super colorls](https://github.com/athityakumar/colorls) Ruby script project.
* [delta](https://github.com/dandavison/delta) ... syntax-highlighting pager for [Git](https://git-scm.com/book/en/v2), [diff](https://en.wikipedia.org/wiki/Diff), and [grep](https://en.wikipedia.org/wiki/Grep) output
* [dust](https://github.com/bootandy/dust) ... [du](https://en.wikipedia.org/wiki/Du_%28Unix%29) + rust = dust ... more intuitive disk utility ... use [deb-get](https://github.com/wimpysworld/deb-get) to install dust.
* [deb-get](https://github.com/wimpysworld/deb-get) ... an alternative to [apt-get](https://linux.die.net/man/8/apt-get) for software not (yet) officially packaged for Debian/Ubuntu, maybe software that is fast moving and newer versions are available from the vendor/project OR maybe you want to use some non-free software that Debian/Ubuntu cannot distribute due to licensing restrictions.
* [duf](https://github.com/muesli/duf), 
* [broot](https://github.com/Canop/broot), 
* [fd](https://github.com/sharkdp/fd), 
* [ripgrep](https://github.com/BurntSushi/ripgrep) ... extremely fast alternative to simple [grep](https://en.wikipedia.org/wiki/Grep) which respects your gitignore ... ... of course, there's a [VS Code extension which utilizes ripgrep and fzf](https://github.com/rlivings39/vscode-fzf-quick-open)
* [ag](https://github.com/ggreer/the_silver_searcher) ... code-searching tool similar to [ack](https://beyondgrep.com/) which was itself designed to go beyond simple [grep](https://en.wikipedia.org/wiki/Grep), in being better for programmers with large heterogeneous trees of source code, ack is written in portable Perl 5 and takes advantage of the power of Perl's regular expressions ... since [ag](https://geoff.greer.fm/ag/) is implemented in C and uses [pthreads](https://en.wikipedia.org/wiki/Pthreads), [ag](https://geoff.greer.fm/ag/) is an order of magnitude faster in some cases and [getting even faster](https://geoff.greer.fm/ag/speed/).
* [fzf] ... general purpose command-line fuzzy finder which can be used with any list; files, command history, processes, hostnames, bookmarks, git commits, etc ... of course, there's a [VS Code extension which utilizes ripgrep and fzf](https://github.com/rlivings39/vscode-fzf-quick-open)
* [mcfly], 
* [choose], 
* [jq], 
* [sd], 
* [cheat](https://github.com/cheat/cheat) ... allows for creation and viewing of interactive cheatsheets on the command-line. It was designed to help remind *nix system administrators of options for commands that they use frequently, but not frequently enough to remember.
* [tldr](https://github.com/tldr-pages/tldr) ... collection of community-maintained help pages for command-line tools or cheatsheets which aim to be a simpler, more approachable complement to traditional [man pages](https://en.wikipedia.org/wiki/Man_page)
* [bottom], 
* [glances], 
* [gtop], 
* [hyperfine], 
* [gping], 
* [procs], 
* [httpie], 
* [curlie], 
* [xh], 
* [zoxide], 
* [dog](https://github.com/ogham/dog) ... user-friendly command-line DNS client or DNS lookup utility, like [dig](https://www.diggui.com/dig-command-manual.php) on steroids 


We definitely will need to understand some key features of the UNIX philosophy or what an ideal Unix architecture concept is supposed to be:

* Unix systems use a centralized operating system kernel which manages system and process activities.
* All non-kernel software is organized into separate, kernel-managed processes; this also key for understanding containers and container management systems.
* Unix systems are preemptively multitasking: multiple processes can run at the same time, or within small time slices and nearly at the same time, and any process can be interrupted and moved out of execution by the kernel. Optimizing this thread management is essential for optimizing the performance of computation, which does not matter when we have 100X more compute power than we need -- it's a big deal when compute power limits what we can process.
* Files are stored on disk in a hierarchical file system, with a single top location throughout the system (root, or "/"), with both files and directories, subdirectories, sub-subdirectories, and so on below it. Finding our way around in this file structure is an essential prerequisite to doing anything.
* With few exceptions, devices and some types of communications between processes are managed and visible as files or pseudo-files within the file system hierarchy. This is known as UNIX's "*everything is a file*" philosophy. However, Linus Torvalds is absolutely right in correcting this inaccuracy and pointing out why it's best to think of ["*everything as a STREAM of bytes*"](https://yarchive.net/comp/linux/everything_is_file.html) rather than a file ... it is essential to understand [controlling the streams with ***pipelines***](https://www.gnu.org/software/bash/manual/html_node/Pipelines.html).


### You will NEVER actually be able to finish this pre-requisite lesson from Day 1

> The meta-lesson of this lesson about something as simple as Linux, the Linux development community and the community of open source developers developing better sysadmin tools is about the humility of learning from other human beings.

Of course, this lesson *should* PRECEED any serious work from the [curated list of AWESOME ***bash*** scripts and resources](https://github.com/awesome-lists/awesome-bash), ie because before even using a script, you should really understand what you trying to automate and where this is going to end up ... except, of course, as you use scripting you will learn how [your own fluency in mastering the command line](https://github.com/BrunoScience/notes-on-the-art-of-command-line) was and always will be far less than adequate. That is because this skill is fundamentally about trying to be better at learning how the best of several billion humans learn how to learn ... maybe you can almost learn to keep up with the smartest person you know, but this is really about trying to keep up with the smartest group of 1000 or so learners from the very smartest of smart 1,000,000 people you might be able to know. 
